{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task VI QML-HEP : Quantum representation learning\n",
        "In this task you should implement a simple representation learning scheme based on a contrastive loss:\n",
        "Load the MNIST dataset\n",
        "Write a function which takes an image and prepares a quantum state. This function should have trainable parameters which we want to learn in order to have good quantum representations\n",
        "Create a circuit with which takes two images and embeds both as quantum states with the function you wrote before. Afterwards the circuit should perform a SWAP test between the two states. In the end the measurement should give the fidelity of the quantum states.\n",
        "Train the circuit parameters with a contrastive loss: For two MNIST images in the same class the fidelity should be maximized, while for images of different classes the fidelity should be minimized.\n",
        "\n"
      ],
      "metadata": {
        "id": "X6xIYusgoYnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n"
      ],
      "metadata": {
        "id": "klzi4s9omkAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "BEaRpC--mmcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")\n"
      ],
      "metadata": {
        "id": "-83taKnM6lEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ed9afa-a999-4089-fce9-2eee06722db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "def get_mnist_loaders(batch_size=128):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "    train_dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "    test_dataset = datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "    return train_loader, test_loader\n"
      ],
      "metadata": {
        "id": "4Mm5DOtlm56F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function which takes an image and prepares a quantum state."
      ],
      "metadata": {
        "id": "Y0UeuwSjo7lE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantum Embedding Layer\n",
        "class QuantumEmbedding(nn.Module):\n",
        "    def __init__(self, embedding_dim=32):  # Increased embedding dimension\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(784, embedding_dim)  # Trainable parameters\n",
        "        self.activation = nn.Tanh()  # Non-linearity to mimic quantum state\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)  # Flatten images\n",
        "        return self.activation(self.fc(x))\n",
        "\n"
      ],
      "metadata": {
        "id": "jAYJJHdpnnGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a circuit which embeds two images as quantum states and performs a SWAP test."
      ],
      "metadata": {
        "id": "jxgXbMxBpMoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SWAP test using Cosine Similarity\n",
        "def swap_test(state1, state2):\n",
        "    state1 = nn.functional.normalize(state1, p=2, dim=1)\n",
        "    state2 = nn.functional.normalize(state2, p=2, dim=1)\n",
        "    return torch.matmul(state1, state2.T)  # Compute full pairwise cosine similarity\n"
      ],
      "metadata": {
        "id": "esFnad1inpQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contrastive loss with margin\n",
        "def contrastive_loss(fidelity, same_class, margin=0.5):\n",
        "    fidelity = fidelity.view(-1)\n",
        "    same_class = same_class.view(-1)\n",
        "    pos_loss = (1 - fidelity) ** 2 * same_class\n",
        "    neg_loss = torch.relu(fidelity - margin) ** 2 * (1 - same_class)  # Fixed inversion\n",
        "    return torch.mean(pos_loss + neg_loss)\n"
      ],
      "metadata": {
        "id": "M947vNM1nvJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the circuit parameters with contrastive loss."
      ],
      "metadata": {
        "id": "ytwLPynGpW0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "def train_model(train_loader, epochs=10, lr=0.001):\n",
        "    embedding_dim = 32\n",
        "    model = QuantumEmbedding(embedding_dim).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for (img1, label1), (img2, label2) in zip(train_loader, train_loader):\n",
        "            batch_size = min(img1.shape[0], img2.shape[0])\n",
        "            img1, img2 = img1[:batch_size].to(device), img2[:batch_size].to(device)\n",
        "            label1, label2 = label1[:batch_size].to(device), label2[:batch_size].to(device)\n",
        "\n",
        "            state1 = model(img1)\n",
        "            state2 = model(img2)\n",
        "\n",
        "            fidelity = swap_test(state1, state2)\n",
        "            same_class = (label1.unsqueeze(1) == label2.unsqueeze(0)).float()  # Ensure correct shape\n",
        "            loss = contrastive_loss(fidelity, same_class)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "wPzX8IrXn5R0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation\n",
        "def evaluate_model(test_loader, model):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for img1, label1 in test_loader:\n",
        "            img1, label1 = img1.to(device), label1.to(device)\n",
        "            state1 = model(img1)\n",
        "\n",
        "            for img2, label2 in test_loader:\n",
        "                batch_size = min(img1.shape[0], img2.shape[0])\n",
        "                img2, label2 = img2[:batch_size].to(device), label2[:batch_size].to(device)\n",
        "                state2 = model(img2)\n",
        "\n",
        "                fidelity = swap_test(state1, state2)\n",
        "                predicted = (fidelity > 0.5).float()\n",
        "                same_class = (label1.unsqueeze(1) == label2.unsqueeze(0)).float()  # Ensure correct shape\n",
        "\n",
        "                correct += (predicted == same_class).sum().item()\n",
        "                total += same_class.numel()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "rlLsRJdSn9YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run training\n",
        "train_loader, test_loader = get_mnist_loaders()\n",
        "trained_model = train_model(train_loader)\n",
        "evaluate_model(test_loader, trained_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtyuPj293km1",
        "outputId": "2cdbf96f-71a8-4682-cb48-331564355ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.011553901243708663\n",
            "Epoch 2, Loss: 0.00855467302391111\n",
            "Epoch 3, Loss: 0.007918420885163329\n",
            "Epoch 4, Loss: 0.007501513936491346\n",
            "Epoch 5, Loss: 0.0072756362542795985\n",
            "Epoch 6, Loss: 0.0070444197167576885\n",
            "Epoch 7, Loss: 0.006870254509842027\n",
            "Epoch 8, Loss: 0.006752091714107533\n",
            "Epoch 9, Loss: 0.006681959520080196\n",
            "Epoch 10, Loss: 0.006554098465223747\n",
            "Accuracy: 85.29%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why this approach?\n",
        "* Instead of using fixed quantum circuits, we implement a QuantumEmbedding. This allows the embedding to learn an optimal feature representation for the MNIST dataset.\n",
        "* Efficient Pairwise Fidelity Computation. Using swap_test() with cosine similarity provides an efficient approximation of quantum fidelity between embeddings. This avoids the complexity of directly simulating quantum circuits while maintaining meaningful comparisons.\n",
        "* Contrastive Loss with Margin.\n",
        "Maximizing fidelity for images of the same class.\n",
        "Minimizing fidelity beyond a margin for images of different classes.\n",
        "* Improved Training Stability. Gradient Clipping and Learning Rate Scheduler .\n",
        "<br>\n",
        "We are using free tier of notebooks which means achiving good accuracy, in limited time and limited resources is tough but using a good apparoch will help us build a good model with limited resources."
      ],
      "metadata": {
        "id": "Eh4GkTZbpfz5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fhjWG08LFHMK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}